{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBkDcYAF8gg4"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/StadynR/HAR-imu-photogrammetry/blob/main/Notebooks/Dataset%201/Photogrammetry%20-%20Best%20Features.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL5s36gHyqIN"
      },
      "source": [
        "# Dataset 1 - Photogrammetry (Best Features)\n",
        "\n",
        "This notebook contains code and explanations for the training and testing of 7 different AI architectures for the task of Human Action Recognition woth best features using time series data obtained from photogrammetry data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8jX8ZM6p7eI"
      },
      "source": [
        "## Access to Google Drive and load dataset\n",
        "\n",
        "You need to create a shortcut in your Drive home to this folder: https://drive.google.com/drive/folders/1k2sAkmRyyctE1uOc19mrixyt2N47-7pt?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-KH1DO0fy53b",
        "outputId": "712f8e7d-0e10-46b8-ad9f-186469fa9148"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-17deaa040e1f>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Drive mount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "#Drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8PQogp0yltI"
      },
      "outputs": [],
      "source": [
        "#Read the document\n",
        "import pandas as pd\n",
        "df=pd.read_excel('/content/drive/MyDrive/Datasets/Dataset 1/United Photogrammetry Movements.xlsx',sheet_name='Hoja1')\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2VoazdSqCS_"
      },
      "source": [
        "## Dataset Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYsCf4ev0_9m"
      },
      "outputs": [],
      "source": [
        "#Data information\n",
        "df.info()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ_fSlPyqVyU"
      },
      "source": [
        "### Dataset information plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qtayunmg1dX1"
      },
      "outputs": [],
      "source": [
        "#Readings per activity\n",
        "countOfActivities = df['labbel'].value_counts()\n",
        "countOfActivities.plot(kind='bar',title='Number of readings by Activity Type',figsize=(14,8),grid=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOVAqlZq10Is"
      },
      "outputs": [],
      "source": [
        "#Visualization\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_activity(activity,df,start=0,stop=20):\n",
        "  # extractRowsOfActivity = (df['labbel'] == activity)  # Output will be true/false.\n",
        "  data = df[:] # data has only rows that are for the requested activity.\n",
        "  # data = data[['FLx','Fly','FLz','FMx','FMy','FMz','FUx','FUy','FUz','ALx','ALy','ALz','AMx','AMy','AMz','AUx','AUy','AUz','EEx','EEy','EEz','EIx','EIy','EIz','Sx','Sy','Sz','Hx','Hy','Hz','WEx','WEy','WEz','WIx','WIy','WIz']] # data has only the accelerometer columns of one IMU.\n",
        "  data = data[['FLx','Fly','FLz','FMx','FMy','FMz','FUx','FUy','FUz','ALx','ALy','ALz','AMx','AMy','AMz']] # data has only the accelerometer columns of one IMU.\n",
        "  data = data[start:stop]\n",
        "\n",
        "  ax = data.plot(subplots=True,figsize=(16,12)) # Plot accelerometer for the activity.\n",
        "  ax = ax.flat\n",
        "  fig = ax[0].get_figure()\n",
        "  for x in ax:\n",
        "    x.legend(loc=\"upper left\")\n",
        "    x.set_yticks([])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNzof2ls3Z5_"
      },
      "outputs": [],
      "source": [
        "plot_activity('extension',df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClgAHo_58Dmb"
      },
      "outputs": [],
      "source": [
        "plot_activity('extension',df,0,100000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soAFuWBl4gQc"
      },
      "source": [
        "### Feature Importance\n",
        "\n",
        "**Method:** Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV3zf5g14gQd"
      },
      "outputs": [],
      "source": [
        "df.iloc[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVUwU19V4gQd"
      },
      "outputs": [],
      "source": [
        "df.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2fqTN7o4gQe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X, X_test, Y, Y_test = train_test_split(df.iloc[:, 2:], df.iloc[:, 0], test_size=.2,random_state=4)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=.2,random_state=4)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dqJwQF84gQe"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Initialize the Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the model to the data\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "def list_importances(features, importances):\n",
        "  zipped = zip(features, importances)\n",
        "  df = pd.DataFrame(list(sorted(zipped, reverse=True, key = lambda x: x[1])), columns =['Features', 'Importance'])\n",
        "  return df\n",
        "\n",
        "features = list(df.columns)[2:]\n",
        "df_importance = list_importances(features, clf.feature_importances_)\n",
        "df_importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mol3Zm0qbnq"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "- Normalizing the measurements to be between 0 and 1.\n",
        "- Transforming the measurements to be in a 3-D array of [samples, timesteps,features].\n",
        "- One hot encoding the activity names.\n",
        "- Breaking the 3-D array into a training and test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0ukz8gYsgdW"
      },
      "source": [
        "### Data Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9o3VGvSY4Lya"
      },
      "outputs": [],
      "source": [
        "#NORMALIZATION\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mms = MinMaxScaler()\n",
        "df['FLx_mms'] = mms.fit_transform(df[['FLx']])\n",
        "df['Fly_mms'] = mms.fit_transform(df[['Fly']])\n",
        "df['FLz_mms'] = mms.fit_transform(df[['FLz']])\n",
        "\n",
        "df['FMx_mms'] = mms.fit_transform(df[['FMx']])\n",
        "df['FMy_mms'] = mms.fit_transform(df[['FMy']])\n",
        "df['FMz_mms'] = mms.fit_transform(df[['FMz']])\n",
        "\n",
        "df['FUx_mms'] = mms.fit_transform(df[['FUx']])\n",
        "df['FUy_mms'] = mms.fit_transform(df[['FUy']])\n",
        "df['FUz_mms'] = mms.fit_transform(df[['FUz']])\n",
        "\n",
        "df['ALx_mms'] = mms.fit_transform(df[['ALx']])\n",
        "df['ALy_mms'] = mms.fit_transform(df[['ALy']])\n",
        "df['ALz_mms'] = mms.fit_transform(df[['ALz']])\n",
        "\n",
        "df['AMx_mms'] = mms.fit_transform(df[['AMx']])\n",
        "df['AMy_mms'] = mms.fit_transform(df[['AMy']])\n",
        "df['AMz_mms'] = mms.fit_transform(df[['AMz']])\n",
        "\n",
        "df['AUx_mms'] = mms.fit_transform(df[['AUx']])\n",
        "df['AUy_mms'] = mms.fit_transform(df[['AUy']])\n",
        "df['AUz_mms'] = mms.fit_transform(df[['AUz']])\n",
        "\n",
        "df['EEx_mms'] = mms.fit_transform(df[['EEx']])\n",
        "df['EEy_mms'] = mms.fit_transform(df[['EEy']])\n",
        "df['EEz_mms'] = mms.fit_transform(df[['EEz']])\n",
        "\n",
        "df['EIx_mms'] = mms.fit_transform(df[['EIx']])\n",
        "df['EIy_mms'] = mms.fit_transform(df[['EIy']])\n",
        "df['EIz_mms'] = mms.fit_transform(df[['EIz']])\n",
        "\n",
        "df['Sx_mms'] = mms.fit_transform(df[['Sx']])\n",
        "df['Sy_mms'] = mms.fit_transform(df[['Sy']])\n",
        "df['Sz_mms'] = mms.fit_transform(df[['Sz']])\n",
        "\n",
        "df['Hx_mms'] = mms.fit_transform(df[['Hx']])\n",
        "df['Hy_mms'] = mms.fit_transform(df[['Hy']])\n",
        "df['Hz_mms'] = mms.fit_transform(df[['Hz']])\n",
        "\n",
        "df['WEx_mms'] = mms.fit_transform(df[['WEx']])\n",
        "df['WEy_mms'] = mms.fit_transform(df[['WEy']])\n",
        "df['WEz_mms'] = mms.fit_transform(df[['WEz']])\n",
        "\n",
        "df['WIx_mms'] = mms.fit_transform(df[['WIx']])\n",
        "df['WIy_mms'] = mms.fit_transform(df[['WIy']])\n",
        "df['WIz_mms'] = mms.fit_transform(df[['WIz']])\n",
        "\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnWx0M5js87G"
      },
      "source": [
        "### Transformation of dimensions as a 3D array\n",
        "\n",
        "Considering the size of the dataset, a number of samples of 200 was considered enough to have good training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKjqVAcoJrYf"
      },
      "outputs": [],
      "source": [
        "# antebrazo_inf_z\t0.100456\n",
        "# antebrazo_med_z\t0.089775\n",
        "# mano_z\t0.085992\n",
        "# muneca_int_z\t0.071872\n",
        "# antebrazo_sup_z\t0.068852\n",
        "# muneca_ext_z\t0.067306\n",
        "# antebrazo_sup_y\t0.039812\n",
        "# codo_int_y\t0.034230\n",
        "# muneca_ext_x\t0.033543\n",
        "# brazo_sup_y\t0.030119\n",
        "# antebrazo_med_x\t0.025780\n",
        "# antebrazo_inf_y\t0.025684\n",
        "# mano_y\t0.025296\n",
        "# muneca_int_x\t0.024138\n",
        "# mano_x\t0.020212"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oXw-Uie9FZm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "nSamplesInEach = 200\n",
        "nFeatures = 15\n",
        "samples = []\n",
        "labels = []\n",
        "for i in range(0,len(df)-nSamplesInEach,nSamplesInEach):\n",
        "  # aix = df['FLx_mms'].values[i:i+nSamplesInEach]\n",
        "  aiy = df['Fly_mms'].values[i:i+nSamplesInEach]\n",
        "  aiz = df['FLz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  amx = df['FMx_mms'].values[i:i+nSamplesInEach]\n",
        "  # amy = df['FMy_mms'].values[i:i+nSamplesInEach]\n",
        "  amz = df['FMz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # asx = df['FUx_mms'].values[i:i+nSamplesInEach]\n",
        "  asy = df['FUy_mms'].values[i:i+nSamplesInEach]\n",
        "  asz = df['FUz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # bix = df['ALx_mms'].values[i:i+nSamplesInEach]\n",
        "  # biy = df['ALy_mms'].values[i:i+nSamplesInEach]\n",
        "  # biz = df['ALz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # bmx = df['AMx_mms'].values[i:i+nSamplesInEach]\n",
        "  # bmy = df['AMy_mms'].values[i:i+nSamplesInEach]\n",
        "  # bmz = df['AMz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # bsx = df['AUx_mms'].values[i:i+nSamplesInEach]\n",
        "  bsy = df['AUy_mms'].values[i:i+nSamplesInEach]\n",
        "  # bsz = df['AUz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # cex = df['EEx_mms'].values[i:i+nSamplesInEach]\n",
        "  # cey = df['EEy_mms'].values[i:i+nSamplesInEach]\n",
        "  # cez = df['EEz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # cix = df['EIx_mms'].values[i:i+nSamplesInEach]\n",
        "  ciy = df['EIy_mms'].values[i:i+nSamplesInEach]\n",
        "  # ciz = df['EIz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  # hx = df['Sx_mms'].values[i:i+nSamplesInEach]\n",
        "  # hy = df['Sy_mms'].values[i:i+nSamplesInEach]\n",
        "  # hz = df['Sz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  mx = df['Hx_mms'].values[i:i+nSamplesInEach]\n",
        "  my = df['Hy_mms'].values[i:i+nSamplesInEach]\n",
        "  mz = df['Hz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  mex = df['WEx_mms'].values[i:i+nSamplesInEach]\n",
        "  # mey = df['WEy_mms'].values[i:i+nSamplesInEach]\n",
        "  mez = df['WEz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  mix = df['WIx_mms'].values[i:i+nSamplesInEach]\n",
        "  # miy = df['WIy_mms'].values[i:i+nSamplesInEach]\n",
        "  miz = df['WIz_mms'].values[i:i+nSamplesInEach]\n",
        "\n",
        "  label = stats.mode(df['labbel'][i:i+nSamplesInEach])\n",
        "  label = label[0][0]\n",
        "\n",
        "  # samples.append([aix, aiy, aiz, amx, amy, amz, asx, asy, asz, bix, biy, biz, bmx, bmy, bmz, bsx, bsy, bsz, cex, cey, cez, cix, ciy, ciz, hx, hy, hz, mx, my, mz, mex, mey, mez, mix, miy, miz])\n",
        "  samples.append([aiy, aiz, amx, amz, asy, asz, bsy, ciy, mx, my, mz, mex, mez, mix, miz])\n",
        "  labels.append(label)\n",
        "\n",
        "# Resulting dimensions of the tensor\n",
        "np.array(samples).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGf2MHB6vCcM"
      },
      "source": [
        "### Reshape\n",
        "\n",
        "This is necessary so that the dimensions of the tensor are in the correct order, that is, to change the shape from (samples, features, timesteps) to (samples, timesteps, features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzFDbedY-wA9"
      },
      "outputs": [],
      "source": [
        "reshaped_s = np.array(samples).reshape(-1,nSamplesInEach,nFeatures)\n",
        "np.array(reshaped_s).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaNfAMNcn-qx"
      },
      "outputs": [],
      "source": [
        "# Length of dataset after preprocessing\n",
        "print(len(reshaped_s))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encoding\n",
        "\n",
        "To make training easier, the labels are encoded to binary values, which are easier to process and map in a neural network."
      ],
      "metadata": {
        "id": "SUWPHVKCvYx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Labels\n",
        "text_labels = labels[:]\n",
        "orig_labels = list(dict.fromkeys(labels)) # Get unique labels\n",
        "for i in range(len(text_labels)):\n",
        "  if text_labels[i] == \"extension\":\n",
        "    text_labels[i] = 0\n",
        "  elif text_labels[i] == \"flexion\":\n",
        "    text_labels[i] = 1\n",
        "  elif text_labels[i] == \"pronacion\":\n",
        "    text_labels[i] = 2\n",
        "  else:\n",
        "    text_labels[i] = 3\n",
        "text_labels = np.array(text_labels)\n",
        "print(orig_labels)\n",
        "print(text_labels)"
      ],
      "metadata": {
        "id": "Ze4AqFLn_D_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(pd.get_dummies(labels))\n",
        "labels[:10]"
      ],
      "metadata": {
        "id": "7XZQ_MYKAX4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify unique encoded labels\n",
        "_, idx = np.unique(labels, axis=0, return_index=True)\n",
        "encoded_labels = labels[np.sort(idx)]\n",
        "print(encoded_labels)"
      ],
      "metadata": {
        "id": "bZ25WYUhm8eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the label list\n",
        "labels.shape"
      ],
      "metadata": {
        "id": "MRIHpOXZAc8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hekaGMStvwcW"
      },
      "source": [
        "## Creation of training, testing and validation splits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWMYJ8niAktf"
      },
      "outputs": [],
      "source": [
        "# Create a kfold object of 5 splits\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adca4Fet3EBB"
      },
      "source": [
        "## Architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQqGRDjwAWT7"
      },
      "source": [
        "### Architecture 1: LSTM(128) + Dropout + Fully Connected + Fully Connected\n",
        "\n",
        "Source: https://www.analyticsvidhya.com/blog/2021/07/implementing-lstm-for-human-activity-recognition-using-smartphone-accelerometer-data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmQDIP0efRTG"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Flatten, Reshape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d_ZzPv3apZ"
      },
      "source": [
        "This simple architecture uses a LSTM layer of 128 neurons to process the time series data, then a dropout layer to prevent overfitting, and two fully connected layers to map the information from previous layers to the 4 outputs.\n",
        "\n",
        "**Loss function:** Categorical Cross Entropy\n",
        "\n",
        "**Optimizer:** Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD2WorQmfUB-"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "  model = Sequential()\n",
        "  # RNN layer\n",
        "  model.add(LSTM(units = 128, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
        "  # Dropout layer\n",
        "  model.add(Dropout(0.5))\n",
        "  # Dense layer with ReLu\n",
        "  model.add(Dense(units = 64, activation='relu'))\n",
        "  # Softmax layer\n",
        "  model.add(Dense(n_outputs, activation = 'softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV5jx6A-Allw"
      },
      "source": [
        "#### Train the model\n",
        "\n",
        "Train the model for 50 epochs in mini-batches of 32 samples (because the dataset is small). This will be done for all the splits made by the kfold. This is 50 iterations over all samples in the `x_train` and `y_train` tensors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialization of train and test\n",
        "\n",
        "X = reshaped_s\n",
        "Y = labels"
      ],
      "metadata": {
        "id": "HhnsbX2Wn4Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch1_train_acc = np.mean(train_accuracies)\n",
        "arch1_train_loss = np.mean(train_losses)\n",
        "arch1_test_acc = np.mean(test_accuracies)\n",
        "arch1_test_loss = np.mean(test_losses)\n",
        "arch1_precision = np.mean(precisions)\n",
        "arch1_recall = np.mean(recalls)\n",
        "arch1_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch1_train_std = np.std(train_accuracies)\n",
        "arch1_test_std = np.std(test_accuracies)\n",
        "arch1_precision_std = np.std(precisions)\n",
        "arch1_recall_std = np.std(recalls)\n",
        "arch1_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch1_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch1_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch1_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch1_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch1_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch1_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch1_f1_score * 100, np.std(f1_scores) * 100))"
      ],
      "metadata": {
        "id": "IAibG35a_hV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBx8rmGwBD9e"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BITPWxTyBKru"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# Create 7 subplots in a grid with 3 rows and 3 columns\n",
        "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(25, 10))\n",
        "\n",
        "axes[0, 0].plot(epochs, acc, 'r', label='Training Accuracy')\n",
        "axes[0, 0].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[0, 0].set_title(\"Architecture 1\")\n",
        "axes[0, 0].set_xlabel('Epochs')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjorl9J9JmWm"
      },
      "source": [
        "### Architecture 2: LSTM(128) + Dropout + LSTM(64) + Dropout + Fully Connected\n",
        "\n",
        "Source: https://github.com/srvds/Human-Activity-Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRXr20-n4pBX"
      },
      "source": [
        "This architecture uses a LSTM layer of 128 neurons to process the time series data, then a dropout layer to prevent overfitting, another LSTM and another dropout layer for improving the previous architecture, and a fully connected layer to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJIMTVGwfkqL"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "  # Initiliazing the sequential model\n",
        "  model = keras.Sequential()\n",
        "  # Add LSTM layer\n",
        "  model.add(LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "  # Adding a dropout layer\n",
        "  model.add(Dropout(0.5))\n",
        "  # Add another LSTM layer\n",
        "  model.add(LSTM(64))\n",
        "  # Adding a dropout layer\n",
        "  model.add(Dropout(0.5))\n",
        "  # Adding a dense output layer with sigmoid activation\n",
        "  model.add(Dense(n_outputs, activation='sigmoid'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  #lost function and optimizer\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ThsnS95NZd"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8L_gHxsgV0j"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch2_train_acc = np.mean(train_accuracies)\n",
        "arch2_train_loss = np.mean(train_losses)\n",
        "arch2_test_acc = np.mean(test_accuracies)\n",
        "arch2_test_loss = np.mean(test_losses)\n",
        "arch2_precision = np.mean(precisions)\n",
        "arch2_recall = np.mean(recalls)\n",
        "arch2_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch2_train_std = np.std(train_accuracies)\n",
        "arch2_test_std = np.std(test_accuracies)\n",
        "arch2_precision_std = np.std(precisions)\n",
        "arch2_recall_std = np.std(recalls)\n",
        "arch2_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch2_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch2_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch2_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch2_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch2_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch2_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch2_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcPxi_Jf5QGY"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7MOBwYsgqeH"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[0, 1].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[0, 1].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[0, 1].set_title(\"Architecture 2\")\n",
        "axes[0, 1].set_xlabel('Epochs')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-8GmVvgLPkF"
      },
      "source": [
        "### Architecture 3: Conv1D(64) + Conv1D(64) + Dropout + Max Pooling + Flatten + Fully Connected + Fully Connected\n",
        "\n",
        "Source: https://github.com/CDAC-lab/ETFA-Workshop/blob/main/CNN%20and%20LSTM%20for%20Human%20Activity%20Recognition.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpyhiIq5gjX"
      },
      "source": [
        "This architecture focuses on convolutional neural networks. The first two layers are 1D convolutions of 64 filters, then a dropout layer to prevent overfitting, a max pooling layer to reduce dimensionality, a flatten layer to use dense layers, and two fully connected layers to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZBciPAVN9Zp"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "\n",
        "  # Define the model\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Add a 1D Convolutional layer with 32 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=64, kernel_size=4, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "\n",
        "  # Add a 1D Convolutional layer with 64 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=64, kernel_size=4, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "\n",
        "  # Add a dropout layer with a rate of 0.5\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # Add a Max Pooling layer with a pool size of 2\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "  # Add a Flatten layer\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add a fully connected layer\n",
        "  model.add(Dense(units=100, activation='relu'))\n",
        "\n",
        "  # Add an output layer\n",
        "  model.add(Dense(units=n_outputs, activation='softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVXBOaU6BJI"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHJsh8r1Ovy0"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch3_train_acc = np.mean(train_accuracies)\n",
        "arch3_train_loss = np.mean(train_losses)\n",
        "arch3_test_acc = np.mean(test_accuracies)\n",
        "arch3_test_loss = np.mean(test_losses)\n",
        "arch3_precision = np.mean(precisions)\n",
        "arch3_recall = np.mean(recalls)\n",
        "arch3_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch3_train_std = np.std(train_accuracies)\n",
        "arch3_test_std = np.std(test_accuracies)\n",
        "arch3_precision_std = np.std(precisions)\n",
        "arch3_recall_std = np.std(recalls)\n",
        "arch3_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch3_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch3_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch3_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch3_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch3_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch3_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch3_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8zCCj346DkH"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY1VHxH2Oy_I"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[0, 2].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[0, 2].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[0, 2].set_title(\"Architecture 3\")\n",
        "axes[0, 2].set_xlabel('Epochs')\n",
        "axes[0, 2].set_ylabel('Loss')\n",
        "axes[0, 2].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYeICGEUNOXQ"
      },
      "source": [
        "### Architecture 4: Conv1D(32) + Max Pooling + LSTM(128) + Dropout + Fully Connected + Fully Connected\n",
        "\n",
        "Source: None, the network was done empyrically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8alqUuL6ePX"
      },
      "source": [
        "This architecture uses a 1D convolutional layer of 32 filters, then a max pooling layer to reduce dimensionality, a LSTM layer of 128 units, a dropout layer to prevent overfitting, and two fully connected layers to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95knfHqWURfF"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "\n",
        "  # Define the model\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Add a 1D Convolutional layer with 32 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\n",
        "  # Add a Max Pooling layer with a pool size of 2\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "  # Add an LSTM layer with 128 units\n",
        "  model.add(LSTM(units=128))\n",
        "\n",
        "  # Add a dropout layer with a rate of 0.5\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # Add a fully connected layer\n",
        "  model.add(Dense(units=64, activation='relu'))\n",
        "\n",
        "  # Add an output layer\n",
        "  model.add(Dense(units=n_outputs, activation='softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W2P6JvV7MH_"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tWPDX_5J2p4"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch4_train_acc = np.mean(train_accuracies)\n",
        "arch4_train_loss = np.mean(train_losses)\n",
        "arch4_test_acc = np.mean(test_accuracies)\n",
        "arch4_test_loss = np.mean(test_losses)\n",
        "arch4_precision = np.mean(precisions)\n",
        "arch4_recall = np.mean(recalls)\n",
        "arch4_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch4_train_std = np.std(train_accuracies)\n",
        "arch4_test_std = np.std(test_accuracies)\n",
        "arch4_precision_std = np.std(precisions)\n",
        "arch4_recall_std = np.std(recalls)\n",
        "arch4_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch4_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch4_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch4_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch4_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch4_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch4_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch4_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFi9zUCa7R2P"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53lIWOqEKF6q"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[0, 3].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[0, 3].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[0, 3].set_title(\"Architecture 4\")\n",
        "axes[0, 3].set_xlabel('Epochs')\n",
        "axes[0, 3].set_ylabel('Loss')\n",
        "axes[0, 3].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgqB0d68NDzF"
      },
      "source": [
        "### Architecture 5: Conv1D(32) + Conv1D(64) + Max Pooling + Bidirectional LSTM(128) + Dropout + Fully Connected + Fully Connected\n",
        "\n",
        "Source: One of the papers suggested using bidirectional LSTM as an improvement for HAR, the added convolutional layers are for testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZk6-Qi17jtA"
      },
      "source": [
        "This architecture uses two layers of 1D convolutions, one using 32 filters and the other using 64 filters, then a max pooling layer to reduce dimensionality, a bidirectional LSTM of 128 neurons, a dropout layer to prevent overfitting, and two fully connected layers to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqUcc5BGNDWA"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Bidirectional, Attention\n",
        "\n",
        "def create_model(n_outputs):\n",
        "\n",
        "  # Define the model\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Add a 1D Convolutional layer with 32 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\n",
        "  # Add a second 1D Convolutional layer with 64 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "\n",
        "  # Add a Max Pooling layer with a pool size of 2\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "  # Add a bidirectional LSTM layer with 128 units\n",
        "  model.add(Bidirectional(LSTM(units=128)))\n",
        "\n",
        "  # Add a dropout layer with a rate of 0.5\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # Add a fully connected layer\n",
        "  model.add(Dense(units=64, activation='relu'))\n",
        "\n",
        "  # Add an output layer\n",
        "  model.add(Dense(units=n_outputs, activation='softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2yeCtTB8I42"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti-3WA0OsjHY"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch5_train_acc = np.mean(train_accuracies)\n",
        "arch5_train_loss = np.mean(train_losses)\n",
        "arch5_test_acc = np.mean(test_accuracies)\n",
        "arch5_test_loss = np.mean(test_losses)\n",
        "arch5_precision = np.mean(precisions)\n",
        "arch5_recall = np.mean(recalls)\n",
        "arch5_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch5_train_std = np.std(train_accuracies)\n",
        "arch5_test_std = np.std(test_accuracies)\n",
        "arch5_precision_std = np.std(precisions)\n",
        "arch5_recall_std = np.std(recalls)\n",
        "arch5_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch5_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch5_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch5_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch5_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch5_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch5_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch5_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hryeI0tE8L-5"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDnjiCzfssxu"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[1, 0].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[1, 0].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[1, 0].set_title(\"Architecture 5\")\n",
        "axes[1, 0].set_xlabel('Epochs')\n",
        "axes[1, 0].set_ylabel('Loss')\n",
        "axes[1, 0].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25g4u1n1xKWv"
      },
      "source": [
        "### Architecture 6: LSTM(128) + Dropout + Reshape + Conv1D(32) + Dropout + Flatten + Fully Connected + Fully Connected\n",
        "\n",
        "Source: Empyrical adaptation of the architechture of the model with convolutional layers at the start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UnZtnjO8kYY"
      },
      "source": [
        "The sixth architecture starts with a LSTM layer, followed by a dropout layer to avoid overfitting and a reshape layer in order to use a convolutional layer. The next layer is a 1D convolution with 32 filters, followed by another dropout layer, and a flatter layer in order to use dense layers. The last two layers are fully connected layers in order to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVE8AokVx3K9"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "\n",
        "  # Define the model\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  # Add an LSTM layer with 128 units\n",
        "  model.add(LSTM(units=128, input_shape=(n_timesteps, n_features)))\n",
        "\n",
        "  # Add a dropout layer with a rate of 0.5\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # Reshape the input data to the correct shape for the Conv1D layer\n",
        "  model.add(Reshape((-1, 128)))\n",
        "\n",
        "  # Add a 1D Convolutional layer with 32 filters and a kernel size of 3\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding='causal'))\n",
        "\n",
        "  # Add a dropout layer with a rate of 0.5\n",
        "  model.add(Dropout(rate=0.5))\n",
        "\n",
        "  # Add a Flatten layer\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add a fully connected layer\n",
        "  model.add(Dense(units=64, activation='relu'))\n",
        "\n",
        "  # Add an output layer\n",
        "  model.add(Dense(units=n_outputs, activation='softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm9-TQ4q9FYW"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGF-_Uj71_D3"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch6_train_acc = np.mean(train_accuracies)\n",
        "arch6_train_loss = np.mean(train_losses)\n",
        "arch6_test_acc = np.mean(test_accuracies)\n",
        "arch6_test_loss = np.mean(test_losses)\n",
        "arch6_precision = np.mean(precisions)\n",
        "arch6_recall = np.mean(recalls)\n",
        "arch6_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch6_train_std = np.std(train_accuracies)\n",
        "arch6_test_std = np.std(test_accuracies)\n",
        "arch6_precision_std = np.std(precisions)\n",
        "arch6_recall_std = np.std(recalls)\n",
        "arch6_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch6_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch6_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch6_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch6_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch6_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch6_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch6_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRCg2w6p9HLP"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFvEGyCf2CUV"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[1, 1].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[1, 1].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[1, 1].set_title(\"Architecture 6\")\n",
        "axes[1, 1].set_xlabel('Epochs')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZSlrlrGwpLQ"
      },
      "source": [
        "### Architecture 7: LSTM(64) + Dropout + Fully Connected + Fully Connected + Fully Connected\n",
        "\n",
        "Source: Empyrical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmTVdWeKwpLR"
      },
      "source": [
        "The final architecture is a very simple one, starting with a LSTM layer, followed by a dropout layer to avoid overfitting and three fully connected layers in order to map the information from previous layers to the 4 outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Avzaf9_FwlFg"
      },
      "outputs": [],
      "source": [
        "def create_model(n_outputs):\n",
        "\n",
        "  model = keras.Sequential()\n",
        "  model.add(LSTM(64,input_shape=(n_timesteps,n_features)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(64,activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byGFqXHTxy7K"
      },
      "source": [
        "#### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmnLzPWCxy7K"
      },
      "outputs": [],
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(X_train, Y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=1)\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      index = int(np.where(encoding == 1)[0])\n",
        "      Y_test_flat.append(index)\n",
        "\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = accuracy_score(Y_test, Y_pred)\n",
        "    test_loss = log_loss(Y_test, model.predict(X_test))\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch7_train_acc = np.mean(train_accuracies)\n",
        "arch7_train_loss = np.mean(train_losses)\n",
        "arch7_test_acc = np.mean(test_accuracies)\n",
        "arch7_test_loss = np.mean(test_losses)\n",
        "arch7_precision = np.mean(precisions)\n",
        "arch7_recall = np.mean(recalls)\n",
        "arch7_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch7_train_std = np.std(train_accuracies)\n",
        "arch7_test_std = np.std(test_accuracies)\n",
        "arch7_precision_std = np.std(precisions)\n",
        "arch7_recall_std = np.std(recalls)\n",
        "arch7_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch7_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch7_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch7_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch7_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch7_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch7_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch7_f1_score * 100, np.std(f1_scores) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC5gB8Zixy7L"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McWEWCOWxy7L"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[1, 2].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[1, 2].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[1, 2].set_title(\"Architecture 7\")\n",
        "axes[1, 2].set_xlabel('Epochs')\n",
        "axes[1, 2].set_ylabel('Loss')\n",
        "axes[1, 2].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4qQbt-iXilA"
      },
      "source": [
        "### Architecture 8: Normalization + Transformer + Normalization + Dense\n",
        "\n",
        "Source: https://www.mdpi.com/1424-8220/22/5/1911"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JstpmMWX6c8"
      },
      "outputs": [],
      "source": [
        "!pip3 install git+https://github.com/tensorflow/addons.git\n",
        "\n",
        "from keras.layers import  Add, MultiHeadAttention, LayerNormalization, Layer, Normalization\n",
        "import math\n",
        "from keras import Model\n",
        "from keras.initializers import TruncatedNormal\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, Callback\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lFGhNtyZznL"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(Layer):\n",
        "    def __init__(self, units, dropout_rate, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "        self.projection = Dense(units, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
        "\n",
        "        self.dropout = Dropout(rate=dropout_rate)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(PositionalEmbedding, self).build(input_shape)\n",
        "\n",
        "        self.position = self.add_weight(\n",
        "            name=\"position\",\n",
        "            shape=(1, input_shape[1], self.units),\n",
        "            initializer=TruncatedNormal(stddev=0.02),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.projection(inputs)\n",
        "        x = x + self.position\n",
        "\n",
        "        return self.dropout(x, training=training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIwd6GlIZznM"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(\n",
        "        self, embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, **kwargs\n",
        "    ):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embed_dim,\n",
        "            dropout=attention_dropout_rate,\n",
        "            kernel_initializer=TruncatedNormal(stddev=0.02),\n",
        "        )\n",
        "\n",
        "        self.dense_0 = Dense(\n",
        "            units=mlp_dim,\n",
        "            activation=\"gelu\",\n",
        "            kernel_initializer=TruncatedNormal(stddev=0.02),\n",
        "        )\n",
        "        self.dense_1 = Dense(\n",
        "            units=embed_dim, kernel_initializer=TruncatedNormal(stddev=0.02)\n",
        "        )\n",
        "\n",
        "        self.dropout_0 = Dropout(rate=dropout_rate)\n",
        "        self.dropout_1 = Dropout(rate=dropout_rate)\n",
        "\n",
        "        self.norm_0 = LayerNormalization(epsilon=1e-5)\n",
        "        self.norm_1 = LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.add_0 = Add()\n",
        "        self.add_1 = Add()\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        # Attention block\n",
        "        x = self.norm_0(inputs)\n",
        "        x = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            training=training,\n",
        "        )\n",
        "        x = self.dropout_0(x, training=training)\n",
        "        x = self.add_0([x, inputs])\n",
        "\n",
        "        # MLP block\n",
        "        y = self.norm_1(x)\n",
        "        y = self.dense_0(y)\n",
        "        y = self.dense_1(y)\n",
        "        y = self.dropout_1(y, training=training)\n",
        "\n",
        "        return self.add_1([x, y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYEKK7pYZznN"
      },
      "outputs": [],
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        embed_dim,\n",
        "        mlp_dim,\n",
        "        num_heads,\n",
        "        num_classes,\n",
        "        dropout_rate,\n",
        "        attention_dropout_rate,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "\n",
        "        # Input (normalization of RAW measurements)\n",
        "        self.input_norm = Normalization()\n",
        "\n",
        "        # Input\n",
        "        self.pos_embs = PositionalEmbedding(embed_dim, dropout_rate)\n",
        "\n",
        "        # Encoder\n",
        "        self.e_layers = [\n",
        "            Encoder(embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        # Output\n",
        "        self.norm = LayerNormalization(epsilon=1e-5)\n",
        "        self.final_layer = Dense(num_classes, kernel_initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.input_norm(inputs)\n",
        "        x = self.pos_embs(x, training=training)\n",
        "\n",
        "        for layer in self.e_layers:\n",
        "            x = layer(x, training=training)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.final_layer(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjP4eLOkLZeC"
      },
      "source": [
        "#### Loss function and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK6QapYViAIb"
      },
      "outputs": [],
      "source": [
        "#Loss\n",
        "def smoothed_sparse_categorical_crossentropy(label_smoothing: float = 0.0):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        num_classes = tf.shape(y_pred)[-1]\n",
        "        y_true = tf.one_hot(y_true, num_classes)\n",
        "\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True, label_smoothing=label_smoothing)\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    return loss_fn\n",
        "\n",
        "def cosine_schedule(base_lr, total_steps, warmup_steps):\n",
        "    def step_fn(epoch):\n",
        "        lr = base_lr\n",
        "        epoch += 1\n",
        "\n",
        "        progress = (epoch - warmup_steps) / float(total_steps - warmup_steps)\n",
        "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
        "\n",
        "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
        "\n",
        "        if warmup_steps:\n",
        "            lr = lr * tf.minimum(1.0, epoch / warmup_steps)\n",
        "\n",
        "        return lr\n",
        "\n",
        "    return step_fn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_labels = np.repeat(text_labels.reshape(text_labels.shape[0], 1), reshaped_s.shape[1], axis=1)"
      ],
      "metadata": {
        "id": "fX7fPrj9iyFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaZxGMgKZznS"
      },
      "outputs": [],
      "source": [
        "amsgrad = False\n",
        "attention_dropout = 0.1\n",
        "batch_size = 32\n",
        "dropout = 0.1\n",
        "embed_layer_size = 128\n",
        "epochs = 50\n",
        "fc_layer_size = 256\n",
        "global_clipnorm = 3\n",
        "label_smoothing = 0.05\n",
        "learning_rate = 0.001\n",
        "num_heads = 8\n",
        "num_layers = 3\n",
        "optimizer = \"adam\"\n",
        "warmup_steps = 10\n",
        "\n",
        "def create_model(n_outputs):\n",
        "\n",
        "  # Generate new model\n",
        "  model = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    embed_dim=embed_layer_size,\n",
        "    mlp_dim=fc_layer_size,\n",
        "    num_heads=num_heads,\n",
        "    num_classes=n_outputs,\n",
        "    dropout_rate=dropout,\n",
        "    attention_dropout_rate=attention_dropout,\n",
        "  )\n",
        "\n",
        "  # adapt on training dataset - must be before model.compile !!!\n",
        "  model.input_norm.adapt(X_train, batch_size=batch_size)\n",
        "\n",
        "  # Select optimizer\n",
        "  if optimizer == \"adam\":\n",
        "    optim = Adam(\n",
        "        global_clipnorm=global_clipnorm,\n",
        "        amsgrad=amsgrad,\n",
        "    )\n",
        "\n",
        "  model.compile(\n",
        "    loss=smoothed_sparse_categorical_crossentropy(label_smoothing=label_smoothing),\n",
        "    optimizer=optim,\n",
        "    metrics=[\"accuracy\"],\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracies = []\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "test_losses = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "Y = text_labels\n",
        "\n",
        "for id, (train_index, test_index) in enumerate(kfold.split(X)):\n",
        "\n",
        "    print(f\"------------------------------------------ SPLIT {id + 1} -------------------------------------------\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "    print(f\"X train length: {len(X_train)}    X test length: {len(X_test)}\")\n",
        "    print(f\"y train length: {len(Y_train)}    y test length: {len(Y_test)}\")\n",
        "\n",
        "    # Get the input shape -> (samples, time steps, features)\n",
        "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], n_outputs\n",
        "    print('n_timesteps: {}, n_features: {}, n_outputs: {}'.format(n_timesteps,n_features, n_outputs))\n",
        "\n",
        "    model = create_model(n_outputs)\n",
        "\n",
        "    history = model.fit(\n",
        "      X_train,\n",
        "      Y_train,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      callbacks=[\n",
        "        LearningRateScheduler(cosine_schedule(base_lr=learning_rate, total_steps=epochs, warmup_steps=warmup_steps))\n",
        "      ],\n",
        "      verbose=0\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    results = model.evaluate(X_test, Y_test, batch_size = 32, verbose = 1)\n",
        "\n",
        "    history_dict = history.history\n",
        "\n",
        "    # Get the historical values for accuracies and losses\n",
        "\n",
        "    acc = history_dict['accuracy']\n",
        "    loss = history_dict['loss']\n",
        "\n",
        "    # Save the last values for accuracies and losses for comparison\n",
        "\n",
        "    train_acc = acc[-1]\n",
        "    train_loss = loss[-1]\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    Y_pred = model.predict(X_test)\n",
        "    Y_pred_aux = model.predict(X_test)\n",
        "    Y_pred = tf.argmax(Y_pred, axis=2)\n",
        "    Y_pred = Y_pred.numpy()\n",
        "    Y_pred_lcalc = [] # For computing loss\n",
        "    Y_pred_flat = []\n",
        "    Y_test_flat = []\n",
        "\n",
        "    for encoding in Y_pred:\n",
        "      yp = encoding[0] # Extract the Y_pred label\n",
        "      Y_pred_flat.append(yp)\n",
        "\n",
        "    for encoding in Y_test:\n",
        "      yt = encoding[0] # Extract the Y_test label\n",
        "      Y_test_flat.append(yt)\n",
        "\n",
        "    Y_pred = tf.constant(Y_pred_flat)\n",
        "    Y_test = tf.constant(Y_test_flat)\n",
        "\n",
        "    test_acc = results[1]\n",
        "    test_loss = results[0]\n",
        "    precision = precision_score(Y_test, Y_pred, average = 'weighted')\n",
        "    recall = recall_score(Y_test, Y_pred, average = 'weighted')\n",
        "    f1score = f1_score(Y_test, Y_pred, average = 'weighted')\n",
        "\n",
        "    test_accuracies.append(test_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1score)\n",
        "\n",
        "    print(\"Train Accuracy: \", train_acc)\n",
        "    print(\"Train Loss: \", train_loss)\n",
        "    print(\"Test Accuracy: \", test_acc)\n",
        "    print(\"Test Loss: \", test_loss)\n",
        "    print(\"Precision: \", precision)\n",
        "    print(\"Recall: \", recall)\n",
        "    print(\"F1 score: \", f1score)\n",
        "    print(f\"-----------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "arch8_train_acc = np.mean(train_accuracies)\n",
        "arch8_train_loss = np.mean(train_losses)\n",
        "arch8_test_acc = np.mean(test_accuracies)\n",
        "arch8_test_loss = np.mean(test_losses)\n",
        "arch8_precision = np.mean(precisions)\n",
        "arch8_recall = np.mean(recalls)\n",
        "arch8_f1_score = np.mean(f1_scores)\n",
        "\n",
        "arch8_train_std = np.std(train_accuracies)\n",
        "arch8_test_std = np.std(test_accuracies)\n",
        "arch8_precision_std = np.std(precisions)\n",
        "arch8_recall_std = np.std(recalls)\n",
        "arch8_f1_score_std = np.std(f1_scores)\n",
        "\n",
        "print(\"Mean Train Accuracy: %.2f%% (+/- %.2f%%)\" % (arch8_train_acc * 100, np.std(train_accuracies) * 100))\n",
        "print(\"Mean Train Loss: %.2f%%\" % (arch8_train_loss * 100))\n",
        "print(\"Mean Test Accuracy: %.2f%% (+/- %.2f%%)\" % (arch8_test_acc * 100, np.std(test_accuracies) * 100))\n",
        "print(\"Mean Test Loss: %.2f%%\" % (arch8_test_loss * 100))\n",
        "print(\"Mean Precision: %.2f%% (+/- %.2f%%)\" % (arch8_precision * 100, np.std(precisions) * 100))\n",
        "print(\"Mean Recall: %.2f%% (+/- %.2f%%)\" % (arch8_recall * 100, np.std(recalls) * 100))\n",
        "print(\"Mean F1 score: %.2f%% (+/- %.2f%%)\" % (arch8_f1_score * 100, np.std(f1_scores) * 100))"
      ],
      "metadata": {
        "id": "xKfM85PvayIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2RP3L4_mhMG"
      },
      "source": [
        "#### Create a graph of accuracy and loss over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkvlh_GKmhMH"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "axes[1, 3].plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "axes[1, 3].plot(epochs, loss, 'g', label='Training loss')\n",
        "axes[1, 3].set_title(\"Architecture 8\")\n",
        "axes[1, 3].set_xlabel('Epochs')\n",
        "axes[1, 3].set_ylabel('Loss')\n",
        "axes[1, 3].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dUYDsdhcTco"
      },
      "source": [
        "## Table Comparison of accuracies of the 8 architechtures\n",
        "\n",
        "After training and testing all the architectures and obtaining their accuracy and loss values, the obtained results are presented in a table to compare the performance of each architecture in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYKZiVe6cTcp"
      },
      "outputs": [],
      "source": [
        "# Architectures labels\n",
        "archs = [\"Architecture 1\", \"Architecture 2\", \"Architecture 3\", \"Architecture 4\", \"Architecture 5\", \"Architecture 6\", \"Architecture 7\", \"Architecture 8\"]\n",
        "# Training accuracies of the architectures\n",
        "train_accs = [arch1_train_acc, arch2_train_acc, arch3_train_acc, arch4_train_acc, arch5_train_acc, arch6_train_acc, arch7_train_acc, arch8_train_acc]\n",
        "# Training losses of the architectures\n",
        "train_losses = [arch1_test_loss, arch2_test_loss, arch3_test_loss, arch4_test_loss, arch5_test_loss, arch6_test_loss, arch7_train_loss, arch8_train_loss]\n",
        "# Testing accuracies of the architectures\n",
        "test_accs = [arch1_test_acc, arch2_test_acc, arch3_test_acc, arch4_test_acc, arch5_test_acc, arch6_test_acc, arch7_test_acc, arch8_test_acc]\n",
        "# Testing losses of the architectures\n",
        "test_losses = [arch1_test_loss, arch2_test_loss, arch3_test_loss, arch4_test_loss, arch5_test_loss, arch6_test_loss, arch7_test_loss, arch8_test_loss]\n",
        "# Precisions of the architectures\n",
        "precisions = [arch1_precision, arch2_precision, arch3_precision, arch4_precision, arch5_precision, arch6_precision, arch7_precision, arch8_precision]\n",
        "# Recalls of the architectures\n",
        "recalls = [arch1_recall, arch2_recall, arch3_recall, arch4_recall, arch5_recall, arch6_recall, arch7_recall, arch8_recall]\n",
        "# F1 scores of the architectures\n",
        "f1_scores = [arch1_f1_score, arch2_f1_score, arch3_f1_score, arch4_f1_score, arch5_f1_score, arch6_f1_score, arch7_f1_score, arch8_f1_score]\n",
        "\n",
        "# Standard deviations\n",
        "train_stds = [arch1_train_std, arch2_train_std, arch3_train_std, arch4_train_std, arch5_train_std, arch6_train_std, arch7_train_std, arch8_train_std]\n",
        "# Testing accuracies of the architectures\n",
        "test_stds = [arch1_test_std, arch2_test_std, arch3_test_std, arch4_test_std, arch5_test_std, arch6_test_std, arch7_test_std, arch8_test_std]\n",
        "# Precisions of the architectures\n",
        "precisions_stds = [arch1_precision_std, arch2_precision_std, arch3_precision_std, arch4_precision_std, arch5_precision_std, arch6_precision_std, arch7_precision_std, arch8_precision_std]\n",
        "# Recalls of the architectures\n",
        "recalls_stds = [arch1_recall_std, arch2_recall_std, arch3_recall_std, arch4_recall_std, arch5_recall_std, arch6_recall_std, arch7_recall_std, arch8_recall_std]\n",
        "# F1 scores of the architectures\n",
        "f1_scores_stds = [arch1_f1_score_std, arch2_f1_score_std, arch3_f1_score_std, arch4_f1_score_std, arch5_f1_score_std, arch6_f1_score_std, arch7_f1_score_std, arch8_f1_score_std]\n",
        "\n",
        "\n",
        "df = pd.DataFrame(list(zip(archs, train_accs, train_stds, train_losses, test_accs, test_stds, test_losses, precisions, precisions_stds, recalls, recalls_stds, f1_scores, f1_scores_stds)),\n",
        "                  columns =['Architectures', 'Training Accuracy', 'Training std', 'Training Loss', 'Test Accuracy', 'Test std', 'Test Loss', 'Precision', 'Precision std', 'Recall', 'Recall std', 'F1 score', 'F1 score std'])\n",
        "df\n",
        "\n",
        "# Defining custom function which returns\n",
        "# the list for df.style.apply() method\n",
        "def highlight_max(s):\n",
        "    is_max = s == s.max()\n",
        "    return ['font-weight: %s' % 'bold' if cell else '' for cell in is_max]\n",
        "\n",
        "\n",
        "# Defining custom function which returns\n",
        "# the list for df.style.apply() method\n",
        "def highlight_min(s):\n",
        "    is_min = s == s.min()\n",
        "    return ['font-weight: %s' % 'bold' if cell else '' for cell in is_min]\n",
        "\n",
        "df.style.apply(highlight_max, subset = ['Training Accuracy', 'Test Accuracy', 'Precision', 'Recall', 'F1 score']).apply(highlight_min, subset = ['Training Loss', 'Test Loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J7I2gxZ8lCN"
      },
      "source": [
        "## Plot of the Performance of Every Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8buxDzlAYXaI"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XuLf8VN8sKa"
      },
      "source": [
        "## Plot of Best Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "eFgN9BSzgkoL",
        "outputId": "750eb877-8a6d-47b4-828d-fb7300f048ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2500x1000 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best = 3\n",
        "\n",
        "if (best <= 4):\n",
        "  best_x = 0\n",
        "  best_y = best - 1\n",
        "else:\n",
        "  best_x = 1\n",
        "  best_y = (best - 1) - 4\n",
        "\n",
        "# Set the spacing between subplots to zero\n",
        "fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "# Hide the other subplots\n",
        "for i in range(2):\n",
        "    for j in range(4):\n",
        "        if i != best_x or j != best_y:\n",
        "            axes[i, j].set_visible(False)\n",
        "\n",
        "display(axes[best_x, best_y].figure)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}